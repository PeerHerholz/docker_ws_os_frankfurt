{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Pandas?**\n",
    "\n",
    "Pandas is a python library with a focus on efficient exploration and manipulation of data.\n",
    "At the core of this library lies the `Dataframe` which is essentially an multidimensional array, that can contain all possible kinds of data, including missing values, in a comprehensive, explicitly labeld form. \n",
    "While we are used to the numpy array comprised of numerical values, which are great for statistical \n",
    "and numerical operations, a Dataframe allows additionally the implementation of common spreadsheet operations \n",
    "that go beyond simple element-wise boradcasting, like grouping by variables, transformations or pivoting.\n",
    "\n",
    "This notebook is meant to be an introduction to the common operations necessary in the neurosciences. It provides a hopefully concise starting point, but is in it's scope not exhaustive.\n",
    "\n",
    "- adapted from the [Python data science handbook](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "please consider supporting the author by pruchasing the [book](http://shop.oreilly.com/product/0636920034919.do)\n",
    "\n",
    "See Documentation:\n",
    "\n",
    "- the pandas [cookbook](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook): a extensive library of useful examples and tricks\n",
    "\n",
    "- [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) including all pandas internal functions and examples of how to implement them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Objects\n",
    "\n",
    "First, let's introduce the main objects of the Pandas library we'll be confronted with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports at the start of your script\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series Object\n",
    "\n",
    "a one-dimensional array of indexed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0]*2)\n",
    "\n",
    "display(data)\n",
    "print('values: ', data.values)\n",
    "print('indices: ', data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[1])\n",
    "display(data[0:4])\n",
    "display(data[1::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Series`` has an *explicitly defined* index associated with the values.\n",
    "\n",
    "This explicit index definition gives the ``Series`` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
    "For example, if we wish, we can use strings as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "display(data)\n",
    "\n",
    "print('-'*40)\n",
    "display(data.index)  # show index\n",
    "\n",
    "print('-'*40)\n",
    "display(data.index[0:2]) # slice-selecting\n",
    "\n",
    "print('-'*40)\n",
    "display(type(data.index[0:2]))\n",
    "\n",
    "print('-'*40)\n",
    "display(data['d'])  # specifiy value by index\n",
    "\n",
    "print('-'*40)\n",
    "print('explicitly selecting subset by index')\n",
    "display(data[data.index[0:3]])\n",
    "values = data[data.index[0:3]]\n",
    "\n",
    "display(values[0])  # extract value\n",
    "display(values['a'])  # extract value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Indexing: `explicit` vs `implicit`indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c','d','e'], index=[1, 3, 5, 7, 9])\n",
    "# explicit index when indexing\n",
    "display(data[1])\n",
    "\n",
    "# implicit index when slicing\n",
    "display(data[1:3])\n",
    "\n",
    "\n",
    "display(data.loc[1:5])  # explicit\n",
    "display(data.iloc[1:5])  # implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as a specialized dictionary\n",
    "\n",
    "constructing a ``Series`` object directly from a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, a ``Series`` will be created where the index is drawn from the sorted keys.\n",
    "From here, typical dictionary-style item access can be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(population['California'])\n",
    "\n",
    "population['California':'Illinois'] # series also supports array-style operations such as slicing, unlike dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main event: the Pandas `DataFrame`\n",
    "two-dimensional array with both flexible row indices and flexible column names.\n",
    "* think of it as an sequence of series, where the initial index of the series defines the row index (the y-axis) and the \"title\" of the series defines it's specific column name (x-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "\n",
    "area = pd.Series(area_dict)  # define a variable containig a series\n",
    "\n",
    "data = pd.DataFrame({'population': population,\n",
    "                       'area': area}) \n",
    "data['density'] = data['population'] / data['area']\n",
    "display(data)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print('indices: ')\n",
    "display(data.index)  \n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print('columns: ')\n",
    "display(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens if series do not share the same indices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_data = pd.Series(list(range(6)), index=['a','b','c','d','e','f'])\n",
    "\n",
    "conflicting_states = pd.DataFrame({'population': population,\n",
    "                       'area': area,\n",
    "                       'dict':conflicting_data}) \n",
    "conflicting_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### additional ways to build a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a set of lists\n",
    "a = list(i for i in range(3))\n",
    "b = list(range(3))\n",
    "\n",
    "df = {'a': a, 'b': b} \n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# from a 2d numpy array\n",
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accessing ``Series`` of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data['area'])  # by column name\n",
    "\n",
    "display(data.area)  # attribute style\n",
    "\n",
    "data.area is data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accessing rows and columns of a Dataframe by array-style indexing\n",
    "- ``loc`` & ``iloc``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.iloc[:3, :2])  # access the first three rows and the first two columns by implicit indexing\n",
    "\n",
    "display(data.loc[:'Illinois', :'population'])  # loc indexer allows the usage of explicit index and column name\n",
    "\n",
    "data.loc[data.density > 100, ['population', 'density']]  # index by masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these conventions can also be used to assign values to specific rows/columns/cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()  # make a copy of your df so you don't overwrite essential data\n",
    "\n",
    "data_copy['age_range'] = np.nan  # creates a new column with none-type values\n",
    "display(data_copy)\n",
    "\n",
    "data_copy.iloc[0, 2] = None  # set specific cell to none-type\n",
    "display(data_copy)\n",
    "\n",
    "data_copy.loc[data_copy.density > 100, ['density']] = '100'\n",
    "display(data_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting null values\n",
    "Pandas data structures have two useful methods for detecting null data: ``isnull()`` and ``notnull()``.\n",
    "Either one will return a Boolean mask over the data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.isna())  \n",
    "\n",
    "display(data_copy.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check present `Datatypes` of your Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.dtypes)\n",
    "\n",
    "display(data_copy.dtypes)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "display(type(data_copy['age_range'][0])) #check type of specific value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our missing values `nan` are treated as float64. Therefore we can still preform numerical operations on this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sum')\n",
    "display(data_copy.sum())  # sum up values of individual columns\n",
    "\n",
    "print('-'*40)\n",
    "print('mean')\n",
    "display(data_copy.mean())  # means of indivdual columns\n",
    "\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort by values with [`.sort_values()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_copy.sort_values('population'))  # sort by values in column\n",
    "display(data_copy.sort_values('population', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return basic descriptive staistics with the [`.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_copy.describe()) # return basic descriptive staistics\n",
    "\n",
    "display(data_copy['density'].describe())  # return basic descriptive staistics of single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "The density colum seems to contain data of the type `\"object\"`. What does this mean and how would you use what you have learned today to locate possible problems in this colum? \n",
    "Try also to use the `.describe`function on the other columns. How would you interpret the different output of `area` and `density`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "\n",
    "#inspecting single cell\n",
    "display(type(data_copy['density'][0]))\n",
    "display(type(data_copy['density'][3]))\n",
    "\n",
    "# use a for loop to iterate over the column values\n",
    "for i in range(len(data_copy['density'])):\n",
    "    print(data_copy['density'][i])\n",
    "    print(type(data_copy['density'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_copy.copy()  # copy your df to prevent data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()  # drop row containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's no good. The 'age_range' column unfortunately contains only missing values, therefore we are left with no data at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_copy.copy()\n",
    "df.dropna(axis='columns')  # drop columns containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but we still lost the 'density' column, because of a single missing value.\n",
    "How would you drop a single row of our DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sub_df manually by slicing\n",
    "display(df)\n",
    "df = data_copy[1:]  # get rid of california\n",
    "display(df)\n",
    "\n",
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract sub_df manually by using the implicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data_copy.drop(data_copy.index[0])\n",
    "display(df)\n",
    "\n",
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop column by explicit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_copy.copy()\n",
    "df =df.drop(['California'])\n",
    "display(df)\n",
    "\n",
    "df = df.drop('age_range', axis=1)  # axis = 1 denotes that we are refering to columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling df.describe() we still see that columns containing different `dtypes` are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `astype`function allows us to make sensible transformations between `dtypes`. This becomes especially apparent, when working with comma-separated files (.csv files) which may contain `strings` instead of `floats`, when following the german convention of separating integer and fractional part of a number with a comma instead of a decimal point (e.g. 8,00 vs 8.00).\n",
    "\n",
    "So let's recast our values to the `flaot64` type and into `string` type to illustrate another aspect of the `.describe()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_copy.copy()\n",
    "df = df.astype('float64')\n",
    "display(df.describe())\n",
    "\n",
    "# or cast to string for dealing with categorical data\n",
    "df = data_copy.copy()\n",
    "df_text = df.astype('str')\n",
    "display(df_text.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also transform our missing values to 0s making it easier to deal with single missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_copy.copy()\n",
    "df = df.fillna(0)  # Replace all NaN elements with 0s\n",
    "display(df)\n",
    "\n",
    "df = data_copy.copy()  # # Replace all NaN elements with 1s\n",
    "df = df.fillna(1)\n",
    "df\n",
    "# display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Datasets: Concat and Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple concatenation with ``pd.concat``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "pd.concat([ser1, ser2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes can be simply split by indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "piece_1, piece_2, piece_3 = df[:3], df[3:7], df[7:] \n",
    "display(piece_1)\n",
    "display(piece_2)\n",
    "display(piece_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pd.concat()` funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([piece_1,piece_2, piece_3])  # combine frames\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "Be careful with overlapping indices. The `ignore_index` parameter merely assigns a new index.\n",
    "Try setting ignore_index to true and compare rows `0 - 2` with the the rows `6 - 8`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_4 = piece_3  # make a copy \n",
    "display(pd.concat([piece_3,piece_1, piece_4], axis=0, join=\"inner\", ignore_index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a little more complex DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['bird', 'polly'], ['monkey', 'jane'], ['dog', 'pavlov'], ['duck', 'konrad'], ['cat', 'erwin']],\n",
    "                    columns=['animal', 'name'])\n",
    "\n",
    "df2 = pd.DataFrame([['e', 5, 'bird'], ['b', 2, 'monkey'],['c', 3, 'cat'], ['d', 4, 'dog'], ['a', 1, 'duck']],\n",
    "                           columns=['letter', 'number', 'animal'])\n",
    "display(df)\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.concat([df, df2], axis=0, join=\"outer\", ignore_index = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "This doesn't look right.\n",
    "Play around with the parameters `axis`, `join`, `ignore_index` to fix the DataFrame. See -> [concat()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "display(pd.concat([df, df2], axis=1, join=\"inner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `merge()`method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df2.columns\n",
    "pd.merge(df, df2,on='animal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ``append()`` method\n",
    "\n",
    "Instead of calling `pd.concat([df, df2])`, you can simply call `df.append(df2)`, when appropiate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['a', 1], ['b', 2]], columns=['strings', 'integers'])\n",
    "df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['strings', 'integers'])\n",
    "\n",
    "display(df.append(df2, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy: Split, Apply, Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The *split* step involves breaking up and grouping a ``DataFrame`` depending on the value of the specified key.\n",
    "- The *apply* step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "- The *combine* step merges the results of these operations into an output array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Planets dataset, from the [Seaborn package](http://seaborn.pydata.org/) adapted from the [kaggle open exoplanet catalogue ](https://www.kaggle.com/mrisdal/open-exoplanet-catalogue.) to have a real world example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic split-apply-combine operation can be computed with the ``groupby()`` method of ``DataFrame``s, passing the name of the desired key column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can apply virtually any common Pandas or NumPy aggregation function, as well as virtually any valid ``DataFrame`` operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('year').describe().T  # descriptive stats for discovered planets by year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select a particular `series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(planets.groupby('method')['distance'].median())  # median distance from Sun in Parsec (3.26 Light-years = 1 Parsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Top methods per year')\n",
    "display(planets.groupby('year')['method'].describe())  # which methods where mainly used in a given year\n",
    "\n",
    "# compare table to graph\n",
    "# from the seaborn visualisation tutorial\n",
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(\"year\", data=planets, aspect=4.0, kind='count',\n",
    "                       hue='method', order=range(1994, 2015))\n",
    "    g.set_ylabels('Number of Planets Discovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration over groups\n",
    "\n",
    "The ``GroupBy`` object supports direct iteration over the groups, returning each group as a ``Series`` or ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, group in planets.groupby('method'):\n",
    "    print(\"{0:30s} shape={1}  type={2}\".format(method, group.shape, type(group)))\n",
    "display(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, group in planets.groupby(['method']):\n",
    "#     display(method)\n",
    "    display(group.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "Use a for-loop like the one above to group the planets DataFrame by year, drop all columns containing missing data and print the result for every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution \n",
    "for year, group in planets.groupby(['year']):\n",
    "    display(year)\n",
    "    group = group.dropna(axis='columns')\n",
    "    display(group.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or use the build-in `get_group` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_planets = planets.groupby(['method']).get_group('Imaging')\n",
    "imaging_planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby(['method', 'year']).get_group(('Radial Velocity', 2014))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving Data\n",
    "Most data that one deals with is either saved in the csv or tsv format.\n",
    "Let's import some relevant [Data](https://www.kaggle.com/nickhould/craft-cans) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally use the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to load and the [`to_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) function to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try excluding the index_col and the sep parameter\n",
    "df = pd.read_csv('data/beers.csv', index_col=0)\n",
    "df.head()\n",
    "df['brewery_id'] = df['brewery_id'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appy some sensible action like dropping some unnecessary columns and sorting by alochol content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(['ibu', 'id', 'style', 'brewery_id'], axis=1)\n",
    "df_cleaned = df_cleaned.sort_values('abv', ascending=False)\n",
    "df_cleaned = df_cleaned[0:5]\n",
    "display(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your cleaned Data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('data/shoppin_list.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers multiple functions to reshape Data. In general these offer the same basic functionaliyt as the groupby function, but excel in efficiency and readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The [`pivot_table`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table) function.\n",
    "\n",
    "Allows for hierarchical and multiindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pd.pivot_table(df,index=[\"style\",\"name\"])\n",
    "pivoted.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some aspect by indices\n",
    "Altbier = pivoted['id']['Altbier']\n",
    "Altbier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply some function using the newly created hierarchical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_info(beer):\n",
    "    print('-'*50)\n",
    "    print(beer)\n",
    "    print('median alochol content (0 = no alcohol, 1 = pure alcohol) : ' + str(pivoted['abv'][beer].median()))\n",
    "    print('median bitterness (International bittering units): ' + str(pivoted['ibu'][beer].median()))\n",
    "    print('median size of beer in ounces: ' + str(pivoted['ounces'][beer].median()))\n",
    "    print('-'*50)\n",
    "    \n",
    "    \n",
    "style_info('Abbey Single Ale')\n",
    "\n",
    "style_info('Altbier')\n",
    "\n",
    "style_info('American Black Ale')\n",
    "style_info('American Blonde Ale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_2 = pd.pivot_table(df,index=[\"name\",\"style\"])\n",
    "display(pivoted_2.T)\n",
    "\n",
    "def beer_info(beer):\n",
    "    print('-'*50)\n",
    "    print(beer)\n",
    "    print('median alochol content (0 = no alcohol, 1 = pure alcohol) : ' + str(pivoted_2['abv'][beer].median()))\n",
    "    print('median bitterness (International bittering units): ' + str(pivoted_2['ibu'][beer].median()))\n",
    "    print('median size of beer in ounces: ' + str(pivoted_2['ounces'][beer].median()))\n",
    "    print('-'*50)\n",
    "    \n",
    "beer_info('10 Degrees of Separation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The [`pivot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html) function\n",
    "- llows more flexibility, but isn't as intuive to use.\n",
    "\n",
    "Let's extract a list of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looks pretty useless atm\n",
    "style = df.pivot(index='id', columns='style', values='name')\n",
    "display(style.head())\n",
    "\n",
    "brews = df.pivot(index='id', columns='brewery_id', values='name')\n",
    "display(brews.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop all missing values and print a list of AIPA brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AIPA brands')\n",
    "aipa = style['American IPA'].dropna()\n",
    "display(aipa[0:20])\n",
    "\n",
    "print('--'*50)\n",
    "print('All brews of brewery with ID \"60\"')\n",
    "\n",
    "# lets drop all missing values and print a list of all brews of brewery \"60\"\n",
    "brews_60 = brews[60].dropna()\n",
    "display(brews_60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The [`.stack()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack) and [`unstack()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack) functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack from columns to index  -> wide to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked = df.stack()\n",
    "display(df_stacked[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack from index to columns -> long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.unstack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The [`.melt()`]() function\n",
    "\n",
    "unpivots a DataFrame from wide format to long format\n",
    "\n",
    "\n",
    "- id_vars[tuple, list, or ndarray, optional] : Column(s) to use as identifier variables.\n",
    "- value_vars[tuple, list, or ndarray, optional]: Column(s) to unpivot. If not specified, uses all columns that are not set as id_vars.\n",
    "- var_name[scalar]: Name to use for the ‘variable’ column. If None it uses frame.columns.name or ‘variable’.\n",
    "- value_name[scalar, default ‘value’]: Name to use for the ‘value’ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = df.melt(id_vars=['name', 'style'], value_vars =['ounces', 'abv'])\n",
    "melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher resources:\n",
    "\n",
    "- [10 miutes to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html): a short introduction for new users\n",
    "\n",
    "- the pandas [tutorial](http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html): a more detailed course divied into specific lessons\n",
    "    \n",
    "- [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) by Wes McKinney (original creator of Pandas)\n",
    "\n",
    "- [Pandas on PyVideo](http://pyvideo.org/search?q=pandas): featured tutorials from Pandas developers and power users. The PyCon tutorials in particular tend to be given by very well-vetted presenters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
